{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: smaller kernel sizes will lead to higher accuracies of classification in fined-tuned image classification\n",
    "# We think this is likely due to the ability of the CNN to detect smaller features between relatively similar images of the same species\n",
    "# Independent Variables: kernel size\n",
    "# Constant Variables: number of layers, types of layers, input shape, epoches, hyperparamaters(depth,padding)\n",
    "# Dependent Variables: Accuracy\n",
    "# Limitations: we are foregoing pure accuracy for experimental reasons - we could get higher accuracy if we tried but we're keeping\n",
    "# things constant for consistancy between models\n",
    "# Currently only using Input, Convolutional, Relu, Pool, and FC/Dense layers. Can add Dense and Dropout if we have time\n",
    "# Reference to www.cs231n.github.io/convolutional-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfu288/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import os, cv2, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(123)  # for reproducibility\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(arr1, arr2):\n",
    "    seed = random.randint(0, 1000)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr1)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "TRAIN_DIR = './training/'\n",
    "TEST_DIR = './validation/'\n",
    "EPOCHS = 10\n",
    "kernels = [(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7)]\n",
    "num_filters = 160\n",
    "input_shape=(150,150,3)\n",
    "input_shape1=(150,150)\n",
    "run_times = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING IN AND FORMATTING IMAGES\n",
      "empty file\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Setup, Read in images, Preprocess images for training\n",
    "TRAIN_IMG, TRAIN_CLS, TEST_IMG, TEST_CLS = ([] for i in range(4))\n",
    "COLS = ['Label', 'Latin Name', 'Common Name', 'Train Images', 'Validation Images']\n",
    "LABELS = pd.read_csv('./monkey_labels.txt', names=COLS, skiprows=1)\n",
    "CLASSES = [x for x in range(0, len(LABELS))]\n",
    "\n",
    "# read in all images\n",
    "# resizing the images to 100x100 to make training faster\n",
    "print(\"READING IN AND FORMATTING IMAGES\")\n",
    "for x in range(0, len(LABELS)):\n",
    "    train_dir = TRAIN_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    test_dir = TEST_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    for file in os.listdir(train_dir):\n",
    "        if not file.endswith('jpg'):\n",
    "            print(\"empty file\")\n",
    "            continue\n",
    "        img = cv2.imread(train_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, input_shape1)\n",
    "            TRAIN_IMG.append(img)\n",
    "            TRAIN_CLS.append(x)\n",
    "    for file in os.listdir(test_dir):\n",
    "        img = cv2.imread(test_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, input_shape1)\n",
    "            TEST_IMG.append(img)\n",
    "            TEST_CLS.append(x)\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "TRAIN_IMG = np.array(TRAIN_IMG)\n",
    "TEST_IMG = np.array(TEST_IMG)\n",
    "TRAIN_CLS = np.array(TRAIN_CLS)\n",
    "TEST_CLS = np.array(TEST_CLS)\n",
    "\n",
    "# Preprocess images\n",
    "# Reshape them to theanos format (channels, hight, width) # changed to tensorflow\n",
    "# Convert to 0-255 to value in [0-1]\n",
    "# TRAIN_IMG = TRAIN_IMG.reshape(TRAIN_IMG.shape[0], 3, 100, 100)\n",
    "# TEST_IMG = TEST_IMG.reshape(TEST_IMG.shape[0], 3, 100, 100)\n",
    "TRAIN_IMG = TRAIN_IMG.astype('float32')\n",
    "TEST_IMG = TEST_IMG.astype('float32')\n",
    "TRAIN_IMG /= 255\n",
    "TEST_IMG /= 255\n",
    "\n",
    "# Reshape class labels\n",
    "TRAIN_CLS = np_utils.to_categorical(TRAIN_CLS, 10)\n",
    "TEST_CLS = np_utils.to_categorical(TEST_CLS, 10)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_data(TRAIN_IMG, TRAIN_CLS)\n",
    "shuffle_data(TEST_IMG, TEST_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running0\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (1, 1) kernel size\n",
      "272/272 [==============================] - 2s 8ms/step\n",
      "Loss:  14.458879470825195  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (2, 2) kernel size\n",
      "272/272 [==============================] - 2s 8ms/step\n",
      "Loss:  1.287239018608542  Accuracy:  0.6213235294117647\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (3, 3) kernel size\n",
      "272/272 [==============================] - 3s 9ms/step\n",
      "Loss:  14.458879358628216  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (4, 4) kernel size\n",
      "272/272 [==============================] - 3s 10ms/step\n",
      "Loss:  1.3315640056834501  Accuracy:  0.6397058823529411\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (5, 5) kernel size\n"
     ]
    }
   ],
   "source": [
    "for i in range(run_times):\n",
    "    print(\"running\" + str(i))\n",
    "    for test_kernel in kernels:\n",
    "        print(\"COMPILING SIMPLE MODEL\")\n",
    "        simple_model = Sequential()\n",
    "        simple_model.add(Conv2D(num_filters, test_kernel, input_shape=input_shape))\n",
    "        simple_model.add(Activation('relu'))\n",
    "        simple_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        simple_model.add(Flatten()) # Converts and connects multi-dimentional convolutional layer into a 1D feature vector to be used for final classification\n",
    "        simple_model.add(Dense(10, activation='softmax'))\n",
    "        simple_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print(\"TRAINING SIMPLE MODEL FOR {} EPOCHS using {} kernel size\".format(EPOCHS, test_kernel)) \n",
    "        history = simple_model.fit(TRAIN_IMG, TRAIN_CLS, batch_size=32, epochs=EPOCHS, verbose=0, validation_split=0.2, shuffle=True)\n",
    "        loss, acc = simple_model.evaluate(TEST_IMG, TEST_CLS, verbose=1)\n",
    "        print(\"Loss: \", loss, \" Accuracy: \", acc)\n",
    "        with open(\"results_simple_cnn.txt\", 'a') as f:\n",
    "            f.write('{{ \"accuracy\":{}, \"epochs\":{}, \"kernel\":\"{}\", \"num_filters\":{}, \"input_shape\":\"{}\" }} \\n'.format(\n",
    "                acc, EPOCHS, test_kernel, num_filters, input_shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
