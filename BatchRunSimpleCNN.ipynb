{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: smaller kernel sizes will lead to higher accuracies of classification in fined-tuned image classification\n",
    "# We think this is likely due to the ability of the CNN to detect smaller features between relatively similar images of the same species\n",
    "# Independent Variables: kernel size\n",
    "# Constant Variables: number of layers, types of layers, input shape, epoches, hyperparamaters(depth,padding)\n",
    "# Dependent Variables: Accuracy\n",
    "# Limitations: we are foregoing pure accuracy for experimental reasons - we could get higher accuracy if we tried but we're keeping\n",
    "# things constant for consistancy between models\n",
    "# Currently only using Input, Convolutional, Relu, Pool, and FC/Dense layers. Can add Dense and Dropout if we have time\n",
    "# Reference to www.cs231n.github.io/convolutional-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfu288/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import os, cv2, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(123)  # for reproducibility\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(arr1, arr2):\n",
    "    seed = random.randint(0, 1000)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr1)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "TRAIN_DIR = './training/'\n",
    "TEST_DIR = './validation/'\n",
    "EPOCHS = 10\n",
    "kernels = [(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7)]\n",
    "num_filters = 210\n",
    "input_shape=(200,200,3)\n",
    "input_shape1=(200,200)\n",
    "run_times = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING IN AND FORMATTING IMAGES\n",
      "empty file\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Setup, Read in images, Preprocess images for training\n",
    "TRAIN_IMG, TRAIN_CLS, TEST_IMG, TEST_CLS = ([] for i in range(4))\n",
    "COLS = ['Label', 'Latin Name', 'Common Name', 'Train Images', 'Validation Images']\n",
    "LABELS = pd.read_csv('./monkey_labels.txt', names=COLS, skiprows=1)\n",
    "CLASSES = [x for x in range(0, len(LABELS))]\n",
    "\n",
    "# read in all images\n",
    "# resizing the images to 100x100 to make training faster\n",
    "print(\"READING IN AND FORMATTING IMAGES\")\n",
    "for x in range(0, len(LABELS)):\n",
    "    train_dir = TRAIN_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    test_dir = TEST_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    for file in os.listdir(train_dir):\n",
    "        if not file.endswith('jpg'):\n",
    "            print(\"empty file\")\n",
    "            continue\n",
    "        img = cv2.imread(train_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, input_shape1)\n",
    "            TRAIN_IMG.append(img)\n",
    "            TRAIN_CLS.append(x)\n",
    "    for file in os.listdir(test_dir):\n",
    "        img = cv2.imread(test_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, input_shape1)\n",
    "            TEST_IMG.append(img)\n",
    "            TEST_CLS.append(x)\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "TRAIN_IMG = np.array(TRAIN_IMG)\n",
    "TEST_IMG = np.array(TEST_IMG)\n",
    "TRAIN_CLS = np.array(TRAIN_CLS)\n",
    "TEST_CLS = np.array(TEST_CLS)\n",
    "\n",
    "# Preprocess images\n",
    "# Reshape them to theanos format (channels, hight, width) # changed to tensorflow\n",
    "# Convert to 0-255 to value in [0-1]\n",
    "# TRAIN_IMG = TRAIN_IMG.reshape(TRAIN_IMG.shape[0], 3, 100, 100)\n",
    "# TEST_IMG = TEST_IMG.reshape(TEST_IMG.shape[0], 3, 100, 100)\n",
    "TRAIN_IMG = TRAIN_IMG.astype('float32')\n",
    "TEST_IMG = TEST_IMG.astype('float32')\n",
    "TRAIN_IMG /= 255\n",
    "TEST_IMG /= 255\n",
    "\n",
    "# Reshape class labels\n",
    "TRAIN_CLS = np_utils.to_categorical(TRAIN_CLS, 10)\n",
    "TEST_CLS = np_utils.to_categorical(TEST_CLS, 10)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_data(TRAIN_IMG, TRAIN_CLS)\n",
    "shuffle_data(TEST_IMG, TEST_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running0\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (1, 1) kernel size\n",
      "272/272 [==============================] - 4s 16ms/step\n",
      "Loss:  14.458879414726706  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (2, 2) kernel size\n",
      "272/272 [==============================] - 5s 18ms/step\n",
      "Loss:  14.518137539134306  Accuracy:  0.09926470588235294\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (3, 3) kernel size\n",
      "272/272 [==============================] - 5s 20ms/step\n",
      "Loss:  1.3930527041940128  Accuracy:  0.6066176470588235\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (4, 4) kernel size\n",
      "272/272 [==============================] - 6s 22ms/step\n",
      "Loss:  1.3333811900194954  Accuracy:  0.6433823529411765\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (5, 5) kernel size\n",
      "272/272 [==============================] - 7s 27ms/step\n",
      "Loss:  14.458879302529727  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (6, 6) kernel size\n",
      "272/272 [==============================] - 8s 31ms/step\n",
      "Loss:  1.6661015117869657  Accuracy:  0.5514705882352942\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (7, 7) kernel size\n",
      "272/272 [==============================] - 10s 37ms/step\n",
      "Loss:  14.458879695219153  Accuracy:  0.10294117647058823\n",
      "running1\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (1, 1) kernel size\n",
      "272/272 [==============================] - 4s 16ms/step\n",
      "Loss:  14.458879302529727  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (2, 2) kernel size\n",
      "272/272 [==============================] - 5s 17ms/step\n",
      "Loss:  1.4148241912617403  Accuracy:  0.6507352941176471\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (3, 3) kernel size\n",
      "272/272 [==============================] - 5s 19ms/step\n",
      "Loss:  14.518137539134306  Accuracy:  0.09926470588235294\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (4, 4) kernel size\n",
      "272/272 [==============================] - 6s 21ms/step\n",
      "Loss:  1.3846075114081888  Accuracy:  0.5919117647058824\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (5, 5) kernel size\n",
      "272/272 [==============================] - 7s 26ms/step\n",
      "Loss:  14.518137539134306  Accuracy:  0.09926470588235294\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (6, 6) kernel size\n",
      "272/272 [==============================] - 8s 31ms/step\n",
      "Loss:  14.518137314740349  Accuracy:  0.09926470588235294\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (7, 7) kernel size\n",
      "272/272 [==============================] - 10s 37ms/step\n",
      "Loss:  14.3403642317828  Accuracy:  0.11029411764705882\n",
      "running2\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (1, 1) kernel size\n",
      "272/272 [==============================] - 4s 15ms/step\n",
      "Loss:  14.458879302529727  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (2, 2) kernel size\n",
      "272/272 [==============================] - 5s 17ms/step\n",
      "Loss:  14.3403642317828  Accuracy:  0.11029411764705882\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (3, 3) kernel size\n",
      "272/272 [==============================] - 5s 20ms/step\n",
      "Loss:  14.458879695219153  Accuracy:  0.10294117647058823\n",
      "COMPILING SIMPLE MODEL\n",
      "TRAINING SIMPLE MODEL FOR 10 EPOCHS using (4, 4) kernel size\n"
     ]
    }
   ],
   "source": [
    "for i in range(run_times):\n",
    "    print(\"running\" + str(i))\n",
    "    for test_kernel in kernels:\n",
    "        print(\"COMPILING SIMPLE MODEL\")\n",
    "        simple_model = Sequential()\n",
    "        simple_model.add(Conv2D(num_filters, test_kernel, input_shape=input_shape))\n",
    "        simple_model.add(Activation('relu'))\n",
    "        simple_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        simple_model.add(Flatten()) # Converts and connects multi-dimentional convolutional layer into a 1D feature vector to be used for final classification\n",
    "        simple_model.add(Dense(10, activation='softmax'))\n",
    "        simple_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print(\"TRAINING SIMPLE MODEL FOR {} EPOCHS using {} kernel size\".format(EPOCHS, test_kernel)) \n",
    "        history = simple_model.fit(TRAIN_IMG, TRAIN_CLS, batch_size=32, epochs=EPOCHS, verbose=0, validation_split=0.2, shuffle=True)\n",
    "        loss, acc = simple_model.evaluate(TEST_IMG, TEST_CLS, verbose=1)\n",
    "        print(\"Loss: \", loss, \" Accuracy: \", acc)\n",
    "        with open(\"results_simple_cnn.txt\", 'a') as f:\n",
    "            f.write('{{ \"accuracy\":{}, \"epochs\":{}, \"kernel\":\"{}\", \"num_filters\":{}, \"input_shape\":\"{}\" }} \\n'.format(\n",
    "                acc, EPOCHS, test_kernel, num_filters, input_shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
