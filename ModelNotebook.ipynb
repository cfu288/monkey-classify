{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfu288/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import os, cv2, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(123)  # for reproducibility\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(arr1, arr2):\n",
    "    seed = random.randint(0, 1000)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr1)\n",
    "    ran = RandomState(seed)\n",
    "    ran.shuffle(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "TRAIN_DIR = './training/'\n",
    "TEST_DIR = './validation/'\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup, Read in images, Preprocess images for training\n",
    "TRAIN_IMG, TRAIN_CLS, TEST_IMG, TEST_CLS = ([] for i in range(4))\n",
    "COLS = ['Label', 'Latin Name', 'Common Name', 'Train Images', 'Validation Images']\n",
    "LABELS = pd.read_csv('./monkey_labels.txt', names=COLS, skiprows=1)\n",
    "CLASSES = [x for x in range(0, len(LABELS))]\n",
    "\n",
    "# read in all images\n",
    "# resizing the images to 100x100 to make training faster\n",
    "print(\"READING IN AND FORMATTING IMAGES\")\n",
    "for x in range(0, len(LABELS)):\n",
    "    train_dir = TRAIN_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    test_dir = TEST_DIR + LABELS.loc[x,'Label'].strip() + '/'\n",
    "    for file in os.listdir(train_dir):\n",
    "        img = cv2.imread(train_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (100, 100))\n",
    "            TRAIN_IMG.append(img)\n",
    "            TRAIN_CLS.append(x)\n",
    "    for file in os.listdir(test_dir):\n",
    "        img = cv2.imread(test_dir + file)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (100, 100))\n",
    "            TEST_IMG.append(img)\n",
    "            TEST_CLS.append(x)\n",
    "\n",
    "\n",
    "# convert to numpy arrays\n",
    "TRAIN_IMG = np.array(TRAIN_IMG)\n",
    "TEST_IMG = np.array(TEST_IMG)\n",
    "TRAIN_CLS = np.array(TRAIN_CLS)\n",
    "TEST_CLS = np.array(TEST_CLS)\n",
    "\n",
    "# Preprocess images\n",
    "# Reshape them to theanos format (channels, hight, width) # changed to tensorflow\n",
    "# Convert to 0-255 to value in [0-1]\n",
    "# TRAIN_IMG = TRAIN_IMG.reshape(TRAIN_IMG.shape[0], 3, 100, 100)\n",
    "# TEST_IMG = TEST_IMG.reshape(TEST_IMG.shape[0], 3, 100, 100)\n",
    "TRAIN_IMG = TRAIN_IMG.astype('float32')\n",
    "TEST_IMG = TEST_IMG.astype('float32')\n",
    "TRAIN_IMG /= 255\n",
    "TEST_IMG /= 255\n",
    "\n",
    "# Reshape class labels\n",
    "TRAIN_CLS = np_utils.to_categorical(TRAIN_CLS, 10)\n",
    "TEST_CLS = np_utils.to_categorical(TEST_CLS, 10)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_data(TRAIN_IMG, TRAIN_CLS)\n",
    "shuffle_data(TEST_IMG, TEST_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model - MINST\n",
    "\n",
    "# This model was used in a tutorial for MINST images, but gets a 50% on our test set\n",
    "# after 10 epoches\n",
    "model = Sequential()\n",
    "model.add(Conv2D(110, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(110, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate Model - Simple\n",
    "\n",
    "# Trying to use the simplest CNN possible - From here we can mess with the kernel and see if kernel size helps \n",
    "# with fine tuned classification\n",
    "# Hypothesis: smaller kernel sizes will lead to higher accuracies of classification in fined-tuned image classification\n",
    "# Independent Variables: kernel size\n",
    "# Constant Variables: number of layers, types of layers, input shape, epoches\n",
    "# Dependent Variables: Accuracy\n",
    "# Limitations: we are foregoing pure accuracy for experimental reasons - we could get higher accuracy if we tried but we're keeping\n",
    "# things constant for consistancy between models\n",
    "# Currently only using Input, Convolutional, Relu, Pool, and FC/Dense layers. Can add Dense and Dropout if we have time\n",
    "# Reference to www.cs231n.github.io/convolutional-networks\n",
    "test_kernel = (3,3)\n",
    "simple_model = Sequential()\n",
    "# INPUT LAYER\n",
    "# CONVOLUTIONAL LAYER\n",
    "# RELU LAYER\n",
    "model.add(Conv2D(110, test_kernel, activation='relu', input_shape=(100,100,3)))\n",
    "# POOL LAYER\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) # Conerts the convolutional layer into a 1D feature vector to be used for final classification\n",
    "# FULLY CONNECTED LAYER\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "print(\"COMPILING MODEL\")\n",
    "# Adam - Modified Gradient Decent - learning rate changes as it nears\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "print(\"TRAINING FOR {} EPOCHS\".format(EPOCHS)) \n",
    "history = model.fit(TRAIN_IMG, TRAIN_CLS, batch_size=32, epochs=EPOCHS, verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "print(\"SAVE MODEL\")\n",
    "model.save('test_model.h5')\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Print a plot of loss and accuracy over epochs and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('test_model.h5')\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "loss, acc = model.evaluate(TEST_IMG, TEST_CLS, verbose=1)\n",
    "print(\"Loss: \", loss, \" Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict images\n",
    "# TODO - Print mispredicted images, the label it predicted, and the correct label\n",
    "'''\n",
    "for i in range(len(TEST_IMG)):\n",
    "    img = TEST_IMG[i]\n",
    "    cls = TEST_CLS[i]\n",
    "    img = np.array([img])\n",
    "    prediction = model.predict(img, verbose=1, steps=1)\n",
    "    print\n",
    "    print \"Class: \", cls\n",
    "    print \"Prediction: \", prediction[0]\n",
    "    max_index = np.argmax(prediction[0])\n",
    "    print \"Predicted Class index: \", max_index\n",
    "    print \"Prediction Correct: \", True if cls[max_index] == 1. else False\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
